{
    "collab_server" : "",
    "contents" : "---\ntitle: \"CLEE011A2404 sidtoolbox\"\noutput: html_document\nauthor: Marzie Rasekh\n---\n# Subgroup identification demonstration on CLEE011A2404\n\n\n```{r load_packaged, message=FALSE, warning=FALSE, include=FALSE}\n\n# or by indices\nlibrary(devtools)\nlibrary(roxygen2)\n\ninstall(\".\")\n# or load it\nlibrary(sidtoolbox)\n# update if changes made\ndocument()\nlibrary(data.table)\nlibrary(stringr)\nlibrary(ggplot2)\n\n```\n\nFirst we load the data in subgroup.data structure using the loadDataset function. \nI have done some minor preprocessing such as removing subject ID and rownames. \nBOR,  HRMNSTAT, and AGEGR1 is presented in the other features. \nSEX, RACE, CUSTG, and INISTG are not informative. \nCOUNTRY, REGION1 and RACE are very correlated. Keeping only one is suggested, in this case REGION1.\nFirst we try all the clinical and lab covariates combined.\n\n# Load data from siddata file\n```{r loadData, echo=FALSE, message=FALSE, warning=FALSE}\ndataset <- fread(input = \"jiwen/siddata.txt\", stringsAsFactors = TRUE)\ndataset <- dataset[, c(\"V1\", \"USUBJID\", \"AGEGR1\", \"COUNTRY\", \"SEX\", \"INISTG\", \"BOR\", \"CUSTG\", \"RACE\", \"HRMNSTAT\") := NULL]\n\n#levels(data$CUSTG) <- c(1, 2, 3, 4)\nlevels(dataset$BONEONLY) <- c(0, 1)\nlevels(dataset$LUNGINV) <- c(0, 1)\nlevels(dataset$LULIINV) <- c(0, 1)\nlevels(dataset$LIVERINV) <- c(0, 1)\nlevels(dataset$LULIINV) <- c(0, 1)\nlevels(dataset$ECOGBL) <- c(0, 1, 2, NA)\nlevels(dataset$OTHMTSI) <- c(0, 1)\nlevels(dataset$NMTSI) <- c(0, 1, 2, 3)\n\n## BOR: est overall response with confirmation PR=Partial response, CR=complete response, SD=stable disease, NCRNPD=non CR non PD, UNK=unknown\n## TTP: time to progression (days)\nfeatures.outcomes <- c(\"CRPRresponse\", \"TTP\")\nfeatures.clinical <- c(\"IND2TRT\", \"AGE\", \"HRMNSTAT\", \"BONEONLY\", \"WGTBL\", \"HGTBL\", \"BMIBL\", \"LUNGINV\", \"LIVERINV\",\"LULIINV\", \"ECOGBL\", \"REGION1\", \"NMTSI\", \"OTHMTSI\", \"SEX_HRMN\")\nfeatures.lab <- c(\"ALT\", \"AST\", \"BILI\", \"CACR\", \"CREAT\", \"HGB\", \"INR\", \"LYM\", \"MG\", \"NEUT\", \"PLAT\", \"K\", \"SODIUM\", \"WBC\" )\noutcomeTypes <- c(\"binary\", \"survival\")\ncovariates <- c(features.lab, features.clinical)\n\n#idx <- apply(X = dataset, MARGIN = 1, FUN = function(row){\n#    sum(is.na(row)) == 0\n#  })\n#dataset <- dataset[idx, ]\n  \nsubgroup.data <- loadDataset(dataset = dataset, \n                             covariates = covariates, \n                             outcomes = features.outcomes, \n                             outcomeTypes = outcomeTypes)\n\n#fwrite(x = subgroup.data$data, file = \"CLEE011A2404.txt\", row.names = FALSE, sep = \"\\t\")\n\nsubgroup.data\n\n```\n\nThen I set some global variables. The minimum size of a subgroup to be found, how deep the rules can go, the significance threshold, and the smallest value for p-value to avoid underflow.\n\n```{r set_global_variables, echo=TRUE}\nSUBGROUP_MIN_SIZE <- 0.1\nMAX_DEPTH <- 4\nP_THRESHOLD <- 0.05\nMIN_P_VALUE <- 10^-10\n\n```\n\n\n## Explore the data\nThis step helps identify covariates to be included in the subgroup discovery.\n\n### Correlation matrix\nCorrelations who one on one relation in your data. \nHighly correlated covariates should be removed.\nHere we get the corrlation between numeric features.\n\n```{r exploreCorrelationMatrix, echo=FALSE, message=FALSE, warning=FALSE}\n\n# examples\nexploreTriangleCorrelationMatrix(subgroup.data = subgroup.data, method = \"spearman\")\nexploreCorrelationMatrix(subgroup.data = subgroup.data)\nexploreDetailedChartCorrelation(subgroup.data = subgroup.data)\n\n\n```\n\n### Association rules\nAssociation rules help us find high level correlations in the data. \nThe rules are controled by support (how large the corresponding subgroup is) and confidence (how many of the total subgroup size follow the rule).\n\nAssociation rules are defined by support and confidence. Support shows us how frequently the rule (left hand side) is in the data, similar to subgroup size. Confidence is the number of times the rule is correct (right hand side | left hand side), and thus is a measure of strength for the rule. The minimum and maximum depth of the rule can be set by min_order and max_order.\n\nBy filtering RHS (right hand side) for the outcome variables you can find immediate subgroups with highest support.\n\n```{r exploreAssociationRules, echo=FALSE, message=FALSE, warning=FALSE}\n\n# res <- exploreAssociationRules(subgroup.data)\nmin_support <- 0.2 # how many samples support the LHS\nmin_confidence <- 0.6 # how many times RHS | LHS is true\nmin_order <- 2 # minimum depth of rules\nmax_order <- MAX_DEPTH # maximum depth of rules\npaste(\"minimum support =\", min_support, \n      \"minimum confidence =\", min_confidence,\n      \"minimum depth =\", min_order,\n      \"maximum depth =\", max_order)\n\na <- capture.output(p <- plotAssociationRules(subgroup.data = subgroup.data, onlyCovariates = TRUE, support = min_support, confidence = min_confidence, min_order = min_order, max_order = max_order))\np\n\na <- capture.output(p <- plotAssociationRules(subgroup.data = subgroup.data, method = \"graph\", measure = \"confidence\", onlyCovariates = TRUE, support = min_support, confidence = min_confidence, min_order = min_order, max_order = max_order))\np\n\na <- capture.output(p <- plotAssociationRules(subgroup.data = subgroup.data, method = \"scatterplot\", measure = \"support\", onlyCovariates = TRUE, support = min_support, confidence = min_confidence, min_order = min_order, max_order = max_order))\np\n\na <- capture.output(p <- plotAssociationRules(subgroup.data = subgroup.data, method = \"two-key plot\", measure = \"support\", onlyCovariates = FALSE, support = min_support, confidence = min_confidence, min_order = min_order, max_order = max_order))\np\n\n#plotAssociationRulesInteractive(subgroup.data = subgroup.data, onlyCovariates = TRUE)\na <- capture.output(rules <- listAssociationRules(subgroup.data = subgroup.data, onlyCovariates = FALSE, support = min_support, confidence = min_confidence, min_order = min_order, max_order = max_order))\n\nas.data.table(rules)\n\n\n\n```\n\n### Conditional inference tree\nConditional inference trees are supervised trees useful to find different subgroups. \nIn a one arm study, the leaves can be intrepreted as subgroups.\nYou can see one tree for each outcome. \n\n<b>Be cautious when intrepreting the survival data as the values will be treated as numeric. </b>\n\n\n```{r exploreDecisionTree, echo=FALSE, message=FALSE, warning=FALSE}\n# on all coavriates\na <- lapply(X = subgroup.data$outcomes, FUN = function(y) {\n  capture.output(p <- exploreConditionalInferenceTree(subgroup.data = subgroup.data, y_idx = y, stump = FALSE, testtype = \"Bonferroni\", significance = P_THRESHOLD, nmin = SUBGROUP_MIN_SIZE, maxdepth = MAX_DEPTH))\n  plot(main = paste(\"all covariates - \", colnames(subgroup.data$data)[y]), p)\n})\n\n```\n\nLet's try the trees on clinical covariates only.\n\n```{r exploreDecisionTree_clinical, echo=FALSE, message=FALSE, warning=FALSE}\n\n# on clinical covariates only \na <- capture.output(clinical.subgroup <- loadDataset(dataset = subgroup.data$data, \n                                 covariates = features.clinical, \n                                 outcomes = features.outcomes, \n                                 outcomeTypes = outcomeTypes))\n# on all coavriates\na <- lapply(X = clinical.subgroup$outcomes, FUN = function(y) {\n  capture.output(p <- exploreConditionalInferenceTree(subgroup.data = clinical.subgroup, y_idx = y, stump = FALSE, testtype = \"Bonferroni\", significance = P_THRESHOLD, nmin = SUBGROUP_MIN_SIZE, maxdepth = MAX_DEPTH))\n  plot(main = paste(\"clinical covariates - \", colnames(subgroup.data$data)[y]), p)\n})\n\n\n```\n\nAnd on lab covariates only.\n\n```{r exploreDecisionTree_lab, echo=FALSE, message=FALSE, warning=FALSE}\n\n# on clinical covariates only \na <- capture.output(\n  lab.subgroup <- loadDataset(dataset = subgroup.data$data, \n                                 covariates = features.lab, \n                                 outcomes = features.outcomes, \n                                 outcomeTypes = outcomeTypes))\n# on all coavriates\na <- lapply(X = lab.subgroup$outcomes, FUN = function(y) {\n  capture.output(p <- exploreConditionalInferenceTree(subgroup.data = lab.subgroup, y_idx = y, stump = FALSE, testtype = \"Bonferroni\", significance = P_THRESHOLD, nmin = SUBGROUP_MIN_SIZE, maxdepth = MAX_DEPTH))\n  plot(main = paste(\"lab covariates - \", colnames(subgroup.data$data)[y]), p)\n})\n\n\n```\n\nYou can use the above information to filter down your features. User knowledge is required to decide which features to eliminate. Note that correlated features will cause errors in the downstream analysis.\n\n## Subgroup discovery\nLet us discover some subgroups.\n\n```{r subgroup_discovery, message=TRUE, warning=TRUE, include=FALSE}\n# set the outcomes you want to run subgroup discovery on\noutcome_columns <- colnames(subgroup.data$data)[subgroup.data$outcomes]\n# save all rules in allRules\nallRules <- subgroup.data$rules\nallRules\n\n```\n\n### Treatment-specific Subgroup Discovery Tool (TSDT)\n<b>\nBattioui, C., Shen, L., Ruberg, S., (2014). <i>A Resampling-based Ensemble Tree Method to Identify\nPatient Subgroups with Enhanced Treatment Effect.</i> JSM proceedings, 2014 </b>\n\n```{r TSDT, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}\n# the true positive / false positive subgroup is\n# subgroup.data$rules\n\nparam <- list(\n  desirable_response = \"increasing\",\n  nsamples = 100, \n  npermutations = 100, \n  maxdepth = MAX_DEPTH, \n  min_subgroup_n_control = SUBGROUP_MIN_SIZE/2, \n  min_subgroup_n_trt = SUBGROUP_MIN_SIZE/2, \n  n_cpu = 1\n)\n\nresTSDT <- lapply(X = outcome_columns, FUN = function(y_idx) {\n  res <- runTSDT(subgroup.data = subgroup.data, \n                     y_idx = y_idx,\n                     desirable_response = param$desirable_response,\n                     nsamples = param$nsamples, \n                     npermutations = param$npermutations, \n                     maxdepth = param$maxdepth,\n                     n_cpu = param$n_cpu)\n  allRules <<- rbind(allRules, \n                    parseTSDTResults(TSDT_table = res, outcome = y_idx, param = param, filter = \"Strong\"))\n  return(res)\n})\n\nresTSDT\n\n```\n\n\n### Optimization approach with Particle Swarm Optimization (PSO)\nHere we will find subgroups for depth 4, 3, 2, and relaxed (any depth) increasing and decreasing the outcomes.\n\n```{r PSO, message=FALSE, warning=FALSE, include=FALSE}\n\n\n# max depth = 4 increasing\nresPSO <- lapply(X = outcome_columns,\n                 FUN = function(y_idx){\n  pso <- runPSO(subgroup.data = subgroup.data, \n                y_idx = y_idx,  \n                desirable_response = \"increasing\", \n                depth = MAX_DEPTH, \n                nmin = SUBGROUP_MIN_SIZE, \n                iterations = 1000)\n  allRules <<- rbind(allRules, \n                     pso)\n  pso\n})\n\n# max depth = 4 decreasing\nresPSO <- lapply(X = outcome_columns,\n                 FUN = function(y_idx){\n  pso <- runPSO(subgroup.data = subgroup.data, \n                y_idx = y_idx,  \n                desirable_response = \"decreasing\", \n                depth = MAX_DEPTH, \n                nmin = SUBGROUP_MIN_SIZE, \n                iterations = 1000)\n  allRules <<- rbind(allRules, \n                     pso)\n  pso\n})\n\n# max depth = 3 increasing\nresPSO <- lapply(X = outcome_columns,\n                 FUN = function(y_idx){\n  pso <- runPSO(subgroup.data = subgroup.data, \n                y_idx = y_idx,  \n                desirable_response = \"increasing\", \n                depth = 3, \n                nmin = SUBGROUP_MIN_SIZE, \n                iterations = 1000)\n  allRules <<- rbind(allRules, \n                     pso)\n  pso\n})\n\n# max depth = 3 decreasing\nresPSO <- lapply(X = outcome_columns,\n                 FUN = function(y_idx){\n  pso <- runPSO(subgroup.data = subgroup.data, \n                y_idx = y_idx,  \n                desirable_response = \"decreasing\", \n                depth = 3, \n                nmin = SUBGROUP_MIN_SIZE, \n                iterations = 1000)\n  allRules <<- rbind(allRules, \n                     pso)\n  pso\n})\n\n\n# max depth = 2 increasing\nresPSO <- lapply(X = outcome_columns,\n                 FUN = function(y_idx){\n  pso <- runPSO(subgroup.data = subgroup.data, \n                y_idx = y_idx,  \n                desirable_response = \"increasing\", \n                depth = 2, \n                nmin = SUBGROUP_MIN_SIZE, \n                iterations = 1000)\n  allRules <<- rbind(allRules, \n                     pso)\n  pso\n})\n\n# max depth = 2 decreasing\nresPSO <- lapply(X = outcome_columns,\n                 FUN = function(y_idx){\n  pso <- runPSO(subgroup.data = subgroup.data, \n                y_idx = y_idx,  \n                desirable_response = \"decreasing\", \n                depth = 2, \n                nmin = SUBGROUP_MIN_SIZE, \n                iterations = 1000)\n  allRules <<- rbind(allRules, \n                     pso)\n  pso\n})\n\n# max depth = relaxed increasing\nresPSO <- lapply(X = outcome_columns,\n                 FUN = function(y_idx){\n  pso <- runPSO(subgroup.data = subgroup.data, \n                y_idx = y_idx,  \n                desirable_response = \"increasing\", \n                nmin = SUBGROUP_MIN_SIZE, \n                iterations = 1000)\n  allRules <<- rbind(allRules, \n                     pso)\n  pso\n})\n\n\n# max depth = relaxed decreasing\nresPSO <- lapply(X = outcome_columns,\n                 FUN = function(y_idx){\n  pso <- runPSO(subgroup.data = subgroup.data, \n                y_idx = y_idx,  \n                desirable_response = \"increasing\", \n                nmin = SUBGROUP_MIN_SIZE, \n                iterations = 1000)\n  allRules <<- rbind(allRules, \n                     pso)\n  pso\n})\n\n\n```\n\n\n## Analyze and compare rules\n\n```{r compare_rules, echo=FALSE, message=FALSE, warning=FALSE}\nthreshold <- -log10(P_THRESHOLD)\nmax_p_value <- -log10(MIN_P_VALUE)\nsummarizeRules <- function(subgroup.data, rules) {\n  N.rules <- nrow(rules)\n  summaryRules <- data.table()\n  \n  allOutcomes <- outcome_columns\n  \n  for (i in c(1:N.rules)) {\n    row <- rules[i]\n    # adding a fix to remove dummy rules wihch were negative controls\n    if (!grepl(x = row$rule, pattern = \"dummy\")) {\n      if (str_length(row$outcome) == 0) {\n        Y <- allOutcomes\n      } else {\n        Y <- row$outcome\n      }\n      for (y in Y) {\n        row$outcome <- y\n        summaryRules <- rbind(summaryRules, row)\n      }\n    }\n    \n  }\n  N.rules <- nrow(summaryRules)\n  N <- nrow(subgroup.data$data)\n  effect_size <- sapply(\n    X = c(1:N.rules),\n    FUN = function(i) {\n      row <- summaryRules[i]\n      sbg_idx <-\n        parseRule(covariates = subgroup.data, rule = row$rule)\n      f <- effectSize(\n        subgroup.data = subgroup.data,\n        y_idx = row$outcome,\n        subgroup_idx = sbg_idx\n      )\n      c(\n        N_ratio = sum(sbg_idx) / N,\n        effect = f[1],\n        pvalue = f[2]\n      )\n    }\n  )\n  summaryRules$N_ratio <- effect_size[1, ]\n  summaryRules$effect_size <- effect_size[2, ]\n  summaryRules$pvalue <- -log10(effect_size[3, ])\n  summaryRules$pvalue[summaryRules$pvalue > max_p_value] <- max_p_value\n  # check TP rule and get accuracy precision recall\n  truth_subgroup <- which(rules$method == \"sim_TP\")\n  if (length(truth_subgroup) > 0) {\n    truth_subgroup <- parseRule(covariates = subgroup.data,\n                                rule = rules[truth_subgroup[1], ]$rule)\n    performance <- sapply(\n      X = c(1:N.rules),\n      FUN = function(i) {\n        row <- summaryRules[i, ]\n        sbg_idx <-\n          parseRule(covariates = subgroup.data, rule = row$rule)\n        TP <- sum(sbg_idx &  truth_subgroup)\n        FP <- sum(sbg_idx & !truth_subgroup)\n        TN <- sum(!sbg_idx & !truth_subgroup)\n        FN <- sum(!sbg_idx &  truth_subgroup)\n        precision <- TP / (TP + FP)\n        recall <- TP / (TP + FN)\n        F1  <- 2 * (recall * precision) / (precision + recall)\n        c(precision = precision,\n          recall = recall,\n          F1 = F1)\n      }\n    )\n    summaryRules$precision <- performance[1, ] * 100\n    summaryRules$recall <- performance[2, ] * 100\n    summaryRules$F1 <- performance[3, ] * 100\n  }\n  return(summaryRules)\n}\n\nrules.data <- summarizeRules(subgroup.data = subgroup.data, rules = allRules)\n#data$log_p_value <- -log10(data$p_value)\n\n\nggplot(\n  data = rules.data,\n  aes(\n    x = effect_size,\n    y = pvalue,\n    shape = outcome,\n    color = method,\n     size = N_ratio\n  )\n \n) +\ngeom_point() +\nggtitle(\"Summary of rules for CLEE011A2404\") +\ngeom_hline(yintercept = threshold)\n\nrules.data <- rules.data[, c(\"rule\", \"outcome\", \"N_ratio\", \"effect_size\", \"pvalue\")]\nas.data.table(rules.data)\n\n```\n\n\n\n",
    "created" : 1565883561756.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1896653270",
    "id" : "39E6B62F",
    "lastKnownWriteTime" : 1565807338,
    "last_content_update" : 1565887810691,
    "path" : "~/sidtoolbox/jiwen.Rmd",
    "project_path" : "jiwen.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}